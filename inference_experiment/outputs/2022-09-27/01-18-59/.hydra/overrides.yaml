- distributed_training.distributed_port=-1
- distributed_training.distributed_world_size=1
- task.data=/mnt/clova_speech/users/seosh/librispeech_model/am/fairseq_audio_data2
- task.labels=wp
- model.w2v_path=/mnt/clova_speech/users/seosh/librispeech_model/am/w2v2/wav2vec_vox_new.pt
- model._name=wav2vec_seq2seq
- criterion._name=label_smoothed_cross_entropy
- common.log_interval=500
- common.tensorboard_logdir=/workspace/tmp_save_dir/mwer_240k_save/tblog/
- checkpoint.save_dir=/workspace/tmp_save_dir/mwer_240k_save
- checkpoint.save_interval_updates=10000
- task.eval_wer_post_process=wordpiece
- +task.greedy_decoding=true
- dataset.max_tokens=1000000
- optimization.lr=[0.00003]
- +model.decoder_dropout=0.1
- +model.decoder_attention_dropout=0.1
- +model.decoder_activation_dropout=0.1
- +model.decoder_layerdrop=0.0
- +criterion.label_smoothing=0.1
- +criterion.mwer_training=true
- +criterion.mwer_training_updates=0
- +criterion.ce_weight=0.3
- +criterion.mwer_weight=0.7
- model.freeze_finetune_updates=10000
- lr_scheduler.phase_ratio=[0.1,0.4,0.5]
- checkpoint.reset_dataloader=true
